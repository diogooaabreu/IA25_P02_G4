{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9edf0b50",
   "metadata": {},
   "source": [
    "# Notebook 1 – Automatic Classification of Olympic Medal Outcomes\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "This notebook focuses on the application of **automatic classification techniques** to the historical Olympic athletes dataset covering the period from **1896 to 2016**. Building upon the exploratory data analysis (EDA) conducted previously, this notebook aims to transform the available data into a predictive framework using supervised machine learning algorithms.\n",
    "\n",
    "The dataset contains detailed information about athletes, events, and Olympic results, allowing the identification of patterns related to athlete characteristics, sports, and competition contexts. By leveraging these features, classification models are trained to predict **medal outcomes** in Olympic events.\n",
    "\n",
    "This notebook follows a structured machine learning workflow, including:\n",
    "\n",
    "- Definition of business goals\n",
    "\n",
    "- Data selection and preparation\n",
    "\n",
    "- Selection and application of classification algorithms\n",
    "\n",
    "- Model evaluation and comparison\n",
    "\n",
    "- Hyperparameter optimization of the selected model\n",
    "\n",
    "The results obtained in this notebook provide a solid baseline for understanding the predictive potential of the dataset.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d657ac17",
   "metadata": {},
   "source": [
    "## 2.  Dataset Loading and Initial Inspection\n",
    "\n",
    "In this section, the Olympic athletes dataset is loaded and an initial inspection is performed to verify its structure, dimensions, and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "829f2a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 271116 entries, 0 to 271115\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   ID      271116 non-null  int64  \n",
      " 1   Name    271116 non-null  object \n",
      " 2   Sex     271116 non-null  object \n",
      " 3   Age     261642 non-null  float64\n",
      " 4   Height  210945 non-null  float64\n",
      " 5   Weight  208241 non-null  float64\n",
      " 6   Team    271116 non-null  object \n",
      " 7   NOC     271116 non-null  object \n",
      " 8   Games   271116 non-null  object \n",
      " 9   Year    271116 non-null  int64  \n",
      " 10  Season  271116 non-null  object \n",
      " 11  City    271116 non-null  object \n",
      " 12  Sport   271116 non-null  object \n",
      " 13  Event   271116 non-null  object \n",
      " 14  Medal   39783 non-null   object \n",
      "dtypes: float64(3), int64(2), object(10)\n",
      "memory usage: 31.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>271116.000000</td>\n",
       "      <td>261642.000000</td>\n",
       "      <td>210945.000000</td>\n",
       "      <td>208241.000000</td>\n",
       "      <td>271116.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>68248.954396</td>\n",
       "      <td>25.556898</td>\n",
       "      <td>175.338970</td>\n",
       "      <td>70.702393</td>\n",
       "      <td>1978.378480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>39022.286345</td>\n",
       "      <td>6.393561</td>\n",
       "      <td>10.518462</td>\n",
       "      <td>14.348020</td>\n",
       "      <td>29.877632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1896.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>34643.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1960.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>68205.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1988.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>102097.250000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>2002.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>135571.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID            Age         Height         Weight  \\\n",
       "count  271116.000000  261642.000000  210945.000000  208241.000000   \n",
       "mean    68248.954396      25.556898     175.338970      70.702393   \n",
       "std     39022.286345       6.393561      10.518462      14.348020   \n",
       "min         1.000000      10.000000     127.000000      25.000000   \n",
       "25%     34643.000000      21.000000     168.000000      60.000000   \n",
       "50%     68205.000000      24.000000     175.000000      70.000000   \n",
       "75%    102097.250000      28.000000     183.000000      79.000000   \n",
       "max    135571.000000      97.000000     226.000000     214.000000   \n",
       "\n",
       "                Year  \n",
       "count  271116.000000  \n",
       "mean     1978.378480  \n",
       "std        29.877632  \n",
       "min      1896.000000  \n",
       "25%      1960.000000  \n",
       "50%      1988.000000  \n",
       "75%      2002.000000  \n",
       "max      2016.000000  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "olympic_df= pd.read_csv(\"athlete_events.csv\")\n",
    "\n",
    "olympic_df.head()\n",
    "olympic_df.shape\n",
    "olympic_df.info()\n",
    "olympic_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a8a31f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3587f0",
   "metadata": {},
   "source": [
    "## 3. Business Goal\n",
    "\n",
    "The main business goal of this notebook is to develop and evaluate **automatic classification models** capable of predicting **Olympic medal outcomes** based on athlete and event characteristics.\n",
    "\n",
    "Using historical data from the Olympic Games (1896–2016), this analysis aims to:\n",
    "\n",
    "- Build supervised machine learning models to classify **whether an athlete wins a medal or not**, based on features such as age, sex, physical attributes, sport, season, and country.\n",
    "\n",
    "- Compare the performance of different classification algorithms and identify the most suitable model for this task.\n",
    "\n",
    "- Optimize the selected model through hyperparameter tuning in order to improve predictive performance.\n",
    "\n",
    "- Provide insights into which athlete and competition features are most relevant for medal prediction.\n",
    "\n",
    "The results of this notebook can support **sports analysts, researchers, and data scientists** in understanding patterns of success in Olympic competitions and serve as a foundation for more advanced predictive and analytical tasks in subsequent notebooks.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a3400e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 4. Selected algorithms\n",
    "\n",
    "In this notebook, several **supervised machine learning classification algorithms** are applied and compared in order to predict Olympic medal outcomes. The selected algorithms were chosen based on their popularity, interpretability, and suitability for classification tasks involving both numerical and categorical features.\n",
    "\n",
    "### 4.1 Logistic Regression\n",
    "\n",
    "Logistic Regression is used as a **baseline classification model**. Despite its simplicity, it is a widely adopted algorithm for binary classification problems and provides easily interpretable results.\n",
    "\n",
    "This algorithm models the probability of an athlete winning a medal as a function of the input features. It is particularly useful for understanding the influence of individual variables on the target outcome and serves as a reference point for comparing more complex models.\n",
    "\n",
    "**Key characteristics:**\n",
    "\n",
    "- Simple and computationally efficient\n",
    "\n",
    "- Suitable for binary classification\n",
    "\n",
    "- Provides interpretable coefficients\n",
    "\n",
    "- Sensitive to feature scaling and multicollinearity\n",
    "\n",
    "\n",
    "### 4.2 Decision Tree Classifier\n",
    "\n",
    "The Decision Tree classifier is a non-linear model that splits the dataset into subsets based on feature values, creating a tree-like structure of decisions. It is capable of capturing complex relationships between features without requiring extensive data preprocessing.\n",
    "\n",
    "Decision Trees are intuitive and easy to visualize, making them useful for explaining classification decisions. However, they are prone to overfitting if not properly constrained.\n",
    "\n",
    "**Key characteristics:**\n",
    "\n",
    "- Handles both numerical and categorical data\n",
    "\n",
    "- Easy to interpret and visualize\n",
    "\n",
    "- Captures non-linear relationships\n",
    "\n",
    "- Prone to overfitting without pruning or depth control\n",
    "\n",
    "\n",
    "### 4.3 Random Forest Classifier\n",
    "\n",
    "The Random Forest classifier is an ensemble learning method that combines multiple Decision Trees to improve classification performance and robustness. By aggregating the predictions of several trees, Random Forest reduces overfitting and improves generalization.\n",
    "\n",
    "This algorithm is particularly well-suited for complex datasets such as Olympic results, where interactions between multiple features may influence medal outcomes.\n",
    "\n",
    "**Key characteristics:**\n",
    "\n",
    "- High predictive performance\n",
    "\n",
    "- Reduces overfitting through ensemble learning\n",
    "\n",
    "- Handles large datasets and feature interactions well\n",
    "\n",
    "- Provides feature importance measures\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17e3e89",
   "metadata": {},
   "source": [
    "## 5. Data Selection Criteria\n",
    "\n",
    "The data selection process was guided by the objective of building a reliable and interpretable **classification model** for predicting Olympic medal outcomes. Only features with potential predictive value and acceptable data quality were selected.\n",
    "\n",
    "### 5.1 Target Variable\n",
    "\n",
    "The target variable used in this classification task is `Medal`, which represents the outcome of an athlete in a specific Olympic event.\n",
    "\n",
    "For the purposes of this notebook, the target variable was transformed into a **binary classification** problem:\n",
    "\n",
    "- `1` – The athlete won a medal (Gold, Silver, or Bronze)\n",
    "\n",
    "- `0` – The athlete did not win a medal\n",
    "\n",
    "This transformation simplifies the classification task, reduces class imbalance issues, and provides a more stable foundation for model training and evaluation.\n",
    "\n",
    "### 5.2 Selected Features\n",
    "\n",
    "The following features were selected as input variables based on their relevance to athlete performance and medal outcomes:\n",
    "\n",
    "- **Age** – Represents the athlete’s age at the time of the competition\n",
    "\n",
    "- **Sex** – Biological sex of the athlete (Male or Female)\n",
    "\n",
    "- **Height** – Athlete’s height in centimeters\n",
    "\n",
    "- **Weight** – Athlete’s weight in kilograms\n",
    "\n",
    "- **Sport** – Type of sport in which the athlete competed\n",
    "\n",
    "- **Season** – Olympic season (Summer or Winter)\n",
    "\n",
    "- **Year** – Year of the Olympic Games\n",
    "\n",
    "- **NOC** – National Olympic Committee code, representing the athlete’s country\n",
    "\n",
    "These variables capture **demographic, physical, temporal, and contextual** aspects that are likely to influence athletic performance.\n",
    "\n",
    "### 5.3 Excluded Features\n",
    "\n",
    "Several attributes were excluded from the modeling process due to limited predictive value or potential issues:\n",
    "\n",
    "- **ID** – Unique identifier with no relevance for prediction\n",
    "\n",
    "- **Name** – High-cardinality textual feature, not suitable for generalization\n",
    "\n",
    "- **Team** – Redundant with the NOC attribute\n",
    "\n",
    "- **Games** – Combination of year and season, redundant with existing features\n",
    "\n",
    "- **City** – High cardinality and low relevance to individual performance\n",
    "\n",
    "- **Event** – Very high cardinality, which could introduce noise and sparsity\n",
    "\n",
    "Excluding these features helps reduce model complexity, minimize noise, and improve generalization performance.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a29621",
   "metadata": {},
   "source": [
    "## 6. Handling Missing Values and Creating the Target\n",
    "\n",
    "In this section, we focus on preparing the dataset for modeling by addressing two key steps:\n",
    "\n",
    "1. **Target Transformation**  \n",
    "   The original `Medal` column contains the type of medal won (Gold, Silver, Bronze) or NaN if the athlete did not win any medal.  \n",
    "   For the purpose of binary classification, we transform this into a new column `Medal_Binary`:\n",
    "   - `1` indicates that the athlete won a medal.\n",
    "   - `0` indicates that the athlete did not win a medal.\n",
    "\n",
    "2. **Handling Missing Values**  \n",
    "   Some numerical features such as `Age`, `Height`, and `Weight` contain missing values.  \n",
    "   To maintain data quality, we fill missing values using the median for each sex category, which provides a more accurate representation than a global median.\n",
    "\n",
    "This preprocessing step ensures that the dataset is clean and ready for machine learning modeling, reducing the risk of biased predictions due to missing or inconsistent data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8484eedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of the target Medal_Binary:\n",
      "Medal_Binary\n",
      "0    231333\n",
      "1     39783\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing values after filling:\n",
      "Age       0\n",
      "Height    0\n",
      "Weight    0\n",
      "dtype: int64\n",
      "\n",
      "Summary after handling missing values and creating the target:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Team</th>\n",
       "      <th>NOC</th>\n",
       "      <th>Games</th>\n",
       "      <th>Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>City</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Event</th>\n",
       "      <th>Medal</th>\n",
       "      <th>Medal_Binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A Dijiang</td>\n",
       "      <td>M</td>\n",
       "      <td>24.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>China</td>\n",
       "      <td>CHN</td>\n",
       "      <td>1992 Summer</td>\n",
       "      <td>1992</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>Basketball Men's Basketball</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A Lamusi</td>\n",
       "      <td>M</td>\n",
       "      <td>23.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>China</td>\n",
       "      <td>CHN</td>\n",
       "      <td>2012 Summer</td>\n",
       "      <td>2012</td>\n",
       "      <td>Summer</td>\n",
       "      <td>London</td>\n",
       "      <td>Judo</td>\n",
       "      <td>Judo Men's Extra-Lightweight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Gunnar Nielsen Aaby</td>\n",
       "      <td>M</td>\n",
       "      <td>24.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1920 Summer</td>\n",
       "      <td>1920</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Antwerpen</td>\n",
       "      <td>Football</td>\n",
       "      <td>Football Men's Football</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Edgar Lindenau Aabye</td>\n",
       "      <td>M</td>\n",
       "      <td>34.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Denmark/Sweden</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1900 Summer</td>\n",
       "      <td>1900</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Paris</td>\n",
       "      <td>Tug-Of-War</td>\n",
       "      <td>Tug-Of-War Men's Tug-Of-War</td>\n",
       "      <td>Gold</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Christine Jacoba Aaftink</td>\n",
       "      <td>F</td>\n",
       "      <td>21.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>NED</td>\n",
       "      <td>1988 Winter</td>\n",
       "      <td>1988</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Calgary</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>Speed Skating Women's 500 metres</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                      Name Sex   Age  Height  Weight            Team  \\\n",
       "0   1                 A Dijiang   M  24.0   180.0    80.0           China   \n",
       "1   2                  A Lamusi   M  23.0   170.0    60.0           China   \n",
       "2   3       Gunnar Nielsen Aaby   M  24.0   179.0    74.0         Denmark   \n",
       "3   4      Edgar Lindenau Aabye   M  34.0   179.0    74.0  Denmark/Sweden   \n",
       "4   5  Christine Jacoba Aaftink   F  21.0   185.0    82.0     Netherlands   \n",
       "\n",
       "   NOC        Games  Year  Season       City          Sport  \\\n",
       "0  CHN  1992 Summer  1992  Summer  Barcelona     Basketball   \n",
       "1  CHN  2012 Summer  2012  Summer     London           Judo   \n",
       "2  DEN  1920 Summer  1920  Summer  Antwerpen       Football   \n",
       "3  DEN  1900 Summer  1900  Summer      Paris     Tug-Of-War   \n",
       "4  NED  1988 Winter  1988  Winter    Calgary  Speed Skating   \n",
       "\n",
       "                              Event Medal  Medal_Binary  \n",
       "0       Basketball Men's Basketball   NaN             0  \n",
       "1      Judo Men's Extra-Lightweight   NaN             0  \n",
       "2           Football Men's Football   NaN             0  \n",
       "3       Tug-Of-War Men's Tug-Of-War  Gold             1  \n",
       "4  Speed Skating Women's 500 metres   NaN             0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Transform Medal into binary\n",
    "\n",
    "# 1 = won a medal (Gold, Silver, Bronze)\n",
    "# 0 = did not win a medal (NaN)\n",
    "olympic_df['Medal_Binary'] = olympic_df['Medal'].notnull().astype(int)\n",
    "\n",
    "# Check the count of each class\n",
    "print(\"Distribution of the target Medal_Binary:\")\n",
    "print(olympic_df['Medal_Binary'].value_counts())\n",
    "\n",
    "# 2. Fill missing values in Age, Height and Weight\n",
    "# Strategy: use median by sex for better accuracy\n",
    "\n",
    "for col in ['Age', 'Height', 'Weight']:\n",
    "    olympic_df[col] = olympic_df.groupby('Sex')[col].transform(\n",
    "        lambda x: x.fillna(x.median())\n",
    "    )\n",
    "\n",
    "# Check if there are still missing values\n",
    "print(\"\\nMissing values after filling:\")\n",
    "print(olympic_df[['Age', 'Height', 'Weight']].isnull().sum())\n",
    "\n",
    "# 3. Final summary\n",
    "print(\"\\nSummary after handling missing values and creating the target:\")\n",
    "display(olympic_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78103ec9",
   "metadata": {},
   "source": [
    "## 7. Encoding of Categorical Variables\n",
    "\n",
    "Machine learning models generally require numerical input. Therefore, categorical variables must be transformed into numeric representations. In this section, we perform the following transformations:\n",
    "\n",
    "1. **Binary Encoding**  \n",
    "   The columns `Sex` and `Season` have only two categories each. They are mapped to numeric values:\n",
    "   - `Sex`: Male → 0, Female → 1\n",
    "   - `Season`: Summer → 0, Winter → 1\n",
    "\n",
    "2. **Label Encoding**  \n",
    "   Columns with multiple unique categories, such as `Sport` and `NOC` (National Olympic Committee), are transformed using label encoding. Each unique category is assigned a unique integer value.\n",
    "\n",
    "This ensures that all features are numerical and ready to be used in machine learning models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "896a7915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example after encoding:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Season</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Sport_Encoded</th>\n",
       "      <th>NOC</th>\n",
       "      <th>NOC_Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>8</td>\n",
       "      <td>CHN</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Judo</td>\n",
       "      <td>32</td>\n",
       "      <td>CHN</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Football</td>\n",
       "      <td>24</td>\n",
       "      <td>DEN</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tug-Of-War</td>\n",
       "      <td>61</td>\n",
       "      <td>DEN</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>53</td>\n",
       "      <td>NED</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex  Season          Sport  Sport_Encoded  NOC  NOC_Encoded\n",
       "0    0       0     Basketball              8  CHN           41\n",
       "1    0       0           Judo             32  CHN           41\n",
       "2    0       0       Football             24  DEN           55\n",
       "3    0       0     Tug-Of-War             61  DEN           55\n",
       "4    1       1  Speed Skating             53  NED          145"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Sex       0\n",
       "Season    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===============================\n",
    "# Encoding of Categorical Variables\n",
    "# ===============================\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1. Convert binary variables\n",
    "olympic_df['Sex'] = olympic_df['Sex'].map({'M': 0, 'F': 1})\n",
    "olympic_df['Season'] = olympic_df['Season'].map({'Summer': 0, 'Winter': 1})\n",
    "\n",
    "# 2. Label Encoding for variables with many unique values\n",
    "le_sport = LabelEncoder()\n",
    "le_noc = LabelEncoder()\n",
    "\n",
    "olympic_df['Sport_Encoded'] = le_sport.fit_transform(olympic_df['Sport'])\n",
    "olympic_df['NOC_Encoded'] = le_noc.fit_transform(olympic_df['NOC'])\n",
    "\n",
    "# 3. Check the result\n",
    "print(\"Example after encoding:\")\n",
    "display(\n",
    "    olympic_df[\n",
    "        ['Sex', 'Season', 'Sport', 'Sport_Encoded', 'NOC', 'NOC_Encoded']\n",
    "    ].head()\n",
    ")\n",
    "\n",
    "# Check if there are still missing values in the encoded columns\n",
    "olympic_df[['Sex', 'Season']].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc2c962",
   "metadata": {},
   "source": [
    "## 8. Data Splitting\n",
    "\n",
    "Before training any machine learning models, we need to divide the dataset into **training** and **test** sets:\n",
    "\n",
    "1. **Feature Selection**  \n",
    "   The input features (`X`) include both numerical and encoded categorical variables that are relevant for predicting medal outcomes:\n",
    "   - Age, Height, Weight\n",
    "   - Sex, Season\n",
    "   - Sport_Encoded, NOC_Encoded  \n",
    "\n",
    "   The target variable (`y`) is `Medal_Binary`, indicating whether the athlete won a medal (1) or not (0).\n",
    "\n",
    "2. **Train-Test Split**  \n",
    "   The dataset is split into:\n",
    "   - **Training set:** 70% of the data, used to train the models\n",
    "   - **Test set:** 30% of the data, used to evaluate model performance  \n",
    "\n",
    "   Stratification by `y` ensures that the proportion of medal winners and non-winners is preserved in both sets.\n",
    "\n",
    "3. **Random State**  \n",
    "   Setting `random_state=42` guarantees reproducibility of the split.\n",
    "\n",
    "Finally, we verify the sizes of the resulting training and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84c0e6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (189781, 7)\n",
      "Test set size: (81335, 7)\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Data Splitting\n",
    "# ===============================\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Feature selection (X) and target (y)\n",
    "X = olympic_df[\n",
    "    [\n",
    "        'Age',\n",
    "        'Height',\n",
    "        'Weight',\n",
    "        'Sex',\n",
    "        'Season',\n",
    "        'Sport_Encoded',\n",
    "        'NOC_Encoded'\n",
    "    ]\n",
    "]\n",
    "\n",
    "y = olympic_df['Medal_Binary']\n",
    "\n",
    "# 2. Split into training (70%) and test (30%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# 3. Check dataset sizes\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Test set size:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d876a3fd",
   "metadata": {},
   "source": [
    "## 9. Model Comparison\n",
    "\n",
    "After training multiple classification models, a comparison was performed\n",
    "to evaluate their effectiveness in predicting Olympic medal outcomes.\n",
    "\n",
    "The models compared in this study include:\n",
    "- Logistic Regression\n",
    "- Decision Tree Classifier\n",
    "- Random Forest (Baseline)\n",
    "- Random Forest (Improved)\n",
    "- Random Forest (Optimized)\n",
    "\n",
    "Due to the strong class imbalance, special attention was given to recall\n",
    "and F1-score for the medalist class rather than accuracy alone.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4e3ee2",
   "metadata": {},
   "source": [
    "## 9.1. Logistic Regression\n",
    "\n",
    "Logistic Regression is used as a baseline binary classification model to predict whether an athlete wins a medal or not.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. **Model Creation**  \n",
    "   We create a `LogisticRegression` model with a maximum of 1000 iterations to ensure convergence, and a fixed `random_state` for reproducibility.\n",
    "\n",
    "2. **Training**  \n",
    "   The model is trained on the training set (`X_train`, `y_train`) using all selected features.\n",
    "\n",
    "3. **Prediction**  \n",
    "   Predictions (`y_pred_lr`) are made on the test set (`X_test`).\n",
    "\n",
    "4. **Evaluation**  \n",
    "   We evaluate the model using:\n",
    "   - Accuracy\n",
    "   - Confusion Matrix\n",
    "   - Classification Report (precision, recall, F1-score)\n",
    "\n",
    "   Since the dataset is highly imbalanced, we pay special attention to the **recall for medal winners**, as this indicates how well the model identifies the minority class.\n",
    "\n",
    "5. **Automatic Analysis**  \n",
    "   Based on the recall score, an automatic interpretation of the model performance is provided to highlight its strengths and weaknesses in predicting medal outcomes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88c2c761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8532857933239073\n",
      "\n",
      "Confusion Matrix:\n",
      "[[69397     3]\n",
      " [11930     5]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92     69400\n",
      "           1       0.62      0.00      0.00     11935\n",
      "\n",
      "    accuracy                           0.85     81335\n",
      "   macro avg       0.74      0.50      0.46     81335\n",
      "weighted avg       0.82      0.85      0.79     81335\n",
      "\n",
      "\n",
      "Results Analysis:\n",
      "Despite achieving a high accuracy, the model performs very poorly in identifying medal-winning athletes. This is due to the strong class imbalance in the dataset, causing the model to favor the majority class (non-medalists).\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Logistic Regression\n",
    "# ===============================\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# 1. Create the model\n",
    "log_reg = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2. Train the model\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# 3. Make predictions\n",
    "y_pred_lr = log_reg.predict(X_test)\n",
    "\n",
    "# ===============================\n",
    "# Evaluation with automatic analysis\n",
    "# ===============================\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, recall_score\n",
    "\n",
    "# Main metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "recall_medal = recall_score(y_test, y_pred_lr)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_lr))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "# Automatic analysis of the results\n",
    "print(\"\\nResults Analysis:\")\n",
    "\n",
    "if recall_medal < 0.1:\n",
    "    print(\n",
    "        \"Despite achieving a high accuracy, the model performs very poorly \"\n",
    "        \"in identifying medal-winning athletes. This is due to the strong \"\n",
    "        \"class imbalance in the dataset, causing the model to favor the \"\n",
    "        \"majority class (non-medalists).\"\n",
    "    )\n",
    "elif recall_medal < 0.5:\n",
    "    print(\n",
    "        \"The model shows a reasonable performance in identifying medal-winning athletes, \"\n",
    "        \"however it still struggles significantly due to data imbalance.\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        \"The model presents a good balance between accuracy and the ability \"\n",
    "        \"to identify medal-winning athletes.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd75c296",
   "metadata": {},
   "source": [
    "## 9.2. Decision Tree Classifier\n",
    "\n",
    "The Decision Tree classifier is a non-linear model that splits the dataset into subsets based on feature values, creating a tree-like structure. It can capture complex relationships between features without requiring extensive preprocessing.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. **Model Creation**  \n",
    "   We create a `DecisionTreeClassifier` with `class_weight='balanced'` to handle the class imbalance in the dataset. A fixed `random_state` ensures reproducibility.\n",
    "\n",
    "2. **Training**  \n",
    "   The model is trained on the training set (`X_train`, `y_train`).\n",
    "\n",
    "3. **Prediction**  \n",
    "   Predictions (`y_pred_dt`) are made on the test set (`X_test`).\n",
    "\n",
    "4. **Evaluation**  \n",
    "   The model is evaluated using:\n",
    "   - Accuracy\n",
    "   - Confusion Matrix\n",
    "   - Classification Report (precision, recall, F1-score)\n",
    "\n",
    "   Special attention is given to the recall of the minority class (medal winners), as the dataset is highly imbalanced.\n",
    "\n",
    "5. **Automatic Analysis**  \n",
    "   Based on the recall score, an automatic interpretation of the model performance is provided to highlight strengths and weaknesses in identifying medal-winning athletes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d8b0a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - Accuracy: 0.8027909264154423\n",
      "\n",
      "Confusion Matrix:\n",
      "[[59274 10126]\n",
      " [ 5914  6021]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88     69400\n",
      "           1       0.37      0.50      0.43     11935\n",
      "\n",
      "    accuracy                           0.80     81335\n",
      "   macro avg       0.64      0.68      0.65     81335\n",
      "weighted avg       0.83      0.80      0.81     81335\n",
      "\n",
      "\n",
      "Results Analysis:\n",
      "The Decision Tree model presents a good balance between accuracy and the ability to identify medal-winning athletes.\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Decision Tree Classifier\n",
    "# ===============================\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 1. Create the model\n",
    "dt_model = DecisionTreeClassifier(random_state=42, class_weight='balanced')  # class balancing\n",
    "\n",
    "# 2. Train the model\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# 3. Make predictions\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# 4. Evaluate the model\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, recall_score\n",
    "\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "recall_medal_dt = recall_score(y_test, y_pred_dt)\n",
    "\n",
    "print(\"Decision Tree - Accuracy:\", accuracy_dt)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_dt))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "\n",
    "# 5. Automatic analysis of the results\n",
    "print(\"\\nResults Analysis:\")\n",
    "\n",
    "if recall_medal_dt < 0.1:\n",
    "    print(\n",
    "        \"Despite achieving a high accuracy, the Decision Tree model performs very poorly \"\n",
    "        \"in identifying medal-winning athletes. This is due to the strong class imbalance \"\n",
    "        \"in the dataset, causing the model to favor the majority class (non-medalists).\"\n",
    "    )\n",
    "elif recall_medal_dt < 0.5:\n",
    "    print(\n",
    "        \"The Decision Tree model shows reasonable performance in identifying medal-winning athletes, \"\n",
    "        \"but it still struggles significantly due to data imbalance.\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        \"The Decision Tree model presents a good balance between accuracy and the ability \"\n",
    "        \"to identify medal-winning athletes.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459b353a",
   "metadata": {},
   "source": [
    "## 9.3. Random Forest Classifier - Two Versions\n",
    "\n",
    "The Random Forest classifier is an ensemble learning method that combines multiple Decision Trees to improve prediction performance and robustness. It is particularly suitable for complex datasets, such as Olympic results, where feature interactions may influence medal outcomes.\n",
    "\n",
    "### Versions:\n",
    "\n",
    "1. **Baseline Version**  \n",
    "   - Uses the default number of trees (`n_estimators=100`)  \n",
    "   - No class balancing  \n",
    "   - Provides a baseline performance for comparison\n",
    "\n",
    "2. **Improved Version**  \n",
    "   - Uses more trees (`n_estimators=200`) for better robustness  \n",
    "   - Applies `class_weight='balanced'` to address class imbalance  \n",
    "   - Expected to improve recall for the minority class (medalists)\n",
    "\n",
    "### Steps:\n",
    "\n",
    "- **Model Creation:** Instantiate the `RandomForestClassifier` for each version.\n",
    "- **Training:** Fit the model on the training set (`X_train`, `y_train`).\n",
    "- **Prediction:** Predict on the test set (`X_test`).\n",
    "- **Evaluation:** Calculate accuracy, confusion matrix, and classification report.\n",
    "- **Visualization:** Plot confusion matrices using heatmaps for clearer interpretation.\n",
    "- **Analysis:** Compare the performance of baseline and improved versions, focusing on recall for medal-winning athletes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03e37c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Random Forest - Two Versions\n",
    "# ===============================\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Baseline Version (default) ---\n",
    "rf_baseline = RandomForestClassifier(\n",
    "    n_estimators=100,       # default number of trees\n",
    "    random_state=42\n",
    ")\n",
    "rf_baseline.fit(X_train, y_train)\n",
    "y_pred_baseline = rf_baseline.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "acc_baseline = accuracy_score(y_test, y_pred_baseline)\n",
    "print(\"=== Random Forest - Baseline Version ===\")\n",
    "print(f\"Accuracy: {acc_baseline:.4f}\\n\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_baseline = confusion_matrix(y_test, y_pred_baseline)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_baseline)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_baseline))\n",
    "\n",
    "# Confusion Matrix Plot\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm_baseline, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix - RF Baseline\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# Analysis in sentence\n",
    "print(\"Results Analysis:\")\n",
    "print(\"The baseline model with 100 trees identifies the majority class (non-medalists) well,\")\n",
    "print(\"but shows low recall for medalists due to class imbalance.\\n\")\n",
    "\n",
    "\n",
    "# --- Improved Version (more trees + class balancing) ---\n",
    "rf_improved = RandomForestClassifier(\n",
    "    n_estimators=200,       # more trees for robustness\n",
    "    class_weight='balanced', # class balancing\n",
    "    random_state=42\n",
    ")\n",
    "rf_improved.fit(X_train, y_train)\n",
    "y_pred_improved = rf_improved.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "acc_improved = accuracy_score(y_test, y_pred_improved)\n",
    "print(\"=== Random Forest - Improved Version ===\")\n",
    "print(f\"Accuracy: {acc_improved:.4f}\\n\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_improved = confusion_matrix(y_test, y_pred_improved)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_improved)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_improved))\n",
    "\n",
    "# Confusion Matrix Plot\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm_improved, annot=True, fmt=\"d\", cmap=\"Greens\")\n",
    "plt.title(\"Confusion Matrix - RF Improved\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# Analysis in sentence\n",
    "print(\"Results Analysis:\")\n",
    "print(\"The improved version with class balancing and more trees increases recall for medalists,\")\n",
    "print(\"reducing majority class bias and providing a more balanced view of the predictions.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfbbb22",
   "metadata": {},
   "source": [
    "## 9.4. Random Forest Optimization (Quick Version)\n",
    "\n",
    "After comparing the baseline and improved Random Forest models, we aim to further enhance performance through **hyperparameter optimization**. \n",
    "\n",
    "### Objective:\n",
    "\n",
    "- Improve recall for medal-winning athletes while maintaining good overall accuracy.\n",
    "- Tune the following hyperparameters:\n",
    "  - `n_estimators`: Number of trees in the forest\n",
    "  - `max_depth`: Maximum depth of each tree\n",
    "  - `criterion`: Function to measure the quality of a split (`gini` or `entropy`)\n",
    "  - `class_weight`: Address class imbalance\n",
    "\n",
    "### Method:\n",
    "\n",
    "- **RandomizedSearchCV** is used instead of GridSearchCV for a faster search.\n",
    "- 10 random combinations of the hyperparameters are evaluated.\n",
    "- 3-fold cross-validation is applied on the training set.\n",
    "- The model is evaluated on the test set using **accuracy**, **confusion matrix**, and **classification report**.\n",
    "- Confusion matrix is visualized using a heatmap for easier interpretation.\n",
    "\n",
    "This approach helps to find a well-performing Random Forest model without performing an exhaustive search, reducing computational time while improving predictive power for the minority class (medalists).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e844a39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting RandomizedSearchCV...\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "\n",
      "Best parameters found:\n",
      "{'n_estimators': 100, 'max_depth': 20, 'criterion': 'entropy', 'class_weight': 'balanced'}\n",
      "\n",
      "Accuracy of the optimized model: 0.8292\n",
      "Confusion Matrix:\n",
      "[[61277  8123]\n",
      " [ 5771  6164]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.90     69400\n",
      "           1       0.43      0.52      0.47     11935\n",
      "\n",
      "    accuracy                           0.83     81335\n",
      "   macro avg       0.67      0.70      0.68     81335\n",
      "weighted avg       0.84      0.83      0.84     81335\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Analysis:\n",
      "The optimized Random Forest model achieves a better balance between precision and recall,\n",
      "identifying medalists more effectively while maintaining high accuracy for the majority class.\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Step 3 – Random Forest Optimization (quick version)\n",
    "# ===============================\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Define the base model ---\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# --- Define the parameter grid ---\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],      # number of trees\n",
    "    'max_depth': [10, 20, None],         # maximum depth\n",
    "    'criterion': ['gini', 'entropy'],    # splitting criterion\n",
    "    'class_weight': ['balanced']         # class balancing\n",
    "}\n",
    "\n",
    "# --- Set up RandomizedSearchCV ---\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,        # number of random combinations\n",
    "    cv=3,             # 3-fold cross-validation\n",
    "    scoring='f1',     # F1 metric\n",
    "    n_jobs=-1,        # use all cores\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# --- Train the RandomizedSearch ---\n",
    "print(\"Starting RandomizedSearchCV...\")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# --- Show the best hyperparameters ---\n",
    "print(\"\\nBest parameters found:\")\n",
    "print(random_search.best_params_)\n",
    "\n",
    "# --- Evaluate the optimized model ---\n",
    "y_pred_optimized = random_search.predict(X_test)\n",
    "\n",
    "acc_optimized = accuracy_score(y_test, y_pred_optimized)\n",
    "cm_optimized = confusion_matrix(y_test, y_pred_optimized)\n",
    "\n",
    "print(f\"\\nAccuracy of the optimized model: {acc_optimized:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_optimized)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_optimized))\n",
    "\n",
    "# --- Confusion Matrix Plot ---\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm_optimized, annot=True, fmt=\"d\", cmap=\"Purples\")\n",
    "plt.title(\"Confusion Matrix - Optimized RF\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# --- Analysis in sentence ---\n",
    "print(\"Results Analysis:\")\n",
    "print(\"The optimized Random Forest model achieves a better balance between precision and recall,\")\n",
    "print(\"identifying medalists more effectively while maintaining high accuracy for the majority class.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fe0a5f",
   "metadata": {},
   "source": [
    "## 10. Model Comparison Summary\n",
    "\n",
    "The table below summarizes the performance of all implemented models on the test set, focusing especially on the recall and F1-score for medal-winning athletes (minority class):\n",
    "\n",
    "| Model                        | Accuracy | Recall (Medal) | F1-score (Medal) | Notes on Performance |\n",
    "|-------------------------------|---------|----------------|-----------------|--------------------|\n",
    "| Logistic Regression           | 0.8533  | 0.0004         | 0.00            | Very poor at identifying medalists due to class imbalance. |\n",
    "| Decision Tree Classifier      | 0.8028  | 0.50           | 0.43            | Balanced recall, moderate F1; overfits less than baseline RF. |\n",
    "| Random Forest - Baseline      | 0.8616  | 0.32           | 0.41            | Identifies majority class well; low recall for medalists. |\n",
    "| Random Forest - Improved      | 0.8418  | 0.40           | 0.42            | Class balancing improves recall for medalists; slightly lower overall accuracy. |\n",
    "| Random Forest - Optimized     | 0.8292  | 0.52           | 0.47            | Best balance between recall and precision for medalists; overall accuracy slightly reduced. |\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- Logistic Regression, while accurate overall, completely fails to identify medal winners.  \n",
    "- Decision Tree improves recall for medalists, but overall accuracy is lower.  \n",
    "- Random Forest models benefit from ensemble learning and class balancing.  \n",
    "- Hyperparameter optimization of Random Forest achieves the best trade-off between identifying medalists and maintaining good accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e6a5b5",
   "metadata": {},
   "source": [
    "## 11. Final Conclusion\n",
    "\n",
    "In this notebook, we developed a machine learning pipeline to automatically predict whether an athlete wins a medal in the Olympic Games based on historical data from 1896 to 2016. The process included data cleaning, handling missing values, encoding categorical features, and splitting the dataset into training and test sets.\n",
    "\n",
    "We applied several classification algorithms—**Logistic Regression, Decision Tree, and Random Forest (including optimized versions)**—and evaluated their performance with a particular focus on the recall for medal-winning athletes, given the strong class imbalance.\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "- **Class imbalance is a critical factor**: Models trained without considering the imbalance (e.g., baseline Random Forest, Logistic Regression) showed high overall accuracy but very poor ability to identify medalists.  \n",
    "- **Decision Tree and Random Forest models handle complex interactions better**, improving recall for medal winners.  \n",
    "- **Class balancing and hyperparameter optimization in Random Forest** significantly enhanced the identification of medalists while maintaining reasonable overall accuracy.  \n",
    "- **Data preprocessing is essential**: Handling missing values, encoding categorical variables, and selecting relevant features substantially impact model performance.  \n",
    "- **Ensemble methods provide robustness**: Random Forest, especially the optimized version, outperformed simpler models by capturing interactions among features and reducing overfitting.  \n",
    "\n",
    "### Overall Recommendation:\n",
    "\n",
    "The optimized Random Forest model achieves the best balance between precision, recall, and overall accuracy. It demonstrates that ensemble methods with careful tuning are the most effective for predicting medal outcomes in highly imbalanced datasets like the Olympic athletes dataset.\n",
    "\n",
    "### Lessons Learned:\n",
    "\n",
    "- Proper handling of class imbalance is crucial for minority class prediction.  \n",
    "- Feature selection and preprocessing significantly influence model quality.  \n",
    "- Hyperparameter tuning can improve predictive power without excessive computational cost.  \n",
    "- Ensemble models like Random Forest are more suitable for complex, high-dimensional datasets with interacting features.  \n",
    "\n",
    "These results provide a strong foundation for future analyses, such as exploring **feature importance**, predicting **specific medal types**, or incorporating additional athlete and event characteristics to further improve model performance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
